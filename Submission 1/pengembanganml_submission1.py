# -*- coding: utf-8 -*-
"""PengembanganML_Submission1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sAG4bzsqH1vOf7AbljpJGmV8ex6UHT-6

# Machine Learning Development Project: Submission 1
## Mental Health Insights: Vulnerable Cancer Patients
- Nama: Nabila Jauza Firjatullah
- Email: nabila060695@gmail.com
- Id Dicoding: billa_firza

### Mount to Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Read File"""

import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/IDCamp2023/Pengembangan ML/Mental Health Dataset.csv')

df.head()

print("==" * 20)
print(" " * 9, "Dataset Information")
print("==" * 20)
df.info()

"""### EDA

- Duplicated Data
"""

print(f"{df.duplicated().sum()}")

"""- Missing Value"""

df.isnull().sum()

# Remove missing values adn reset index

df = df.dropna().reset_index(drop=True)

df.isnull().sum()

"""- Check Max Sequence"""

seq_len = [None] * len(df)

for i,post in enumerate(df['posts']):

    seq_len[i] = len(post.split())

print("==" * 7)
print(f'Max seq: {max(seq_len)}')
print("==" * 7)

"""### Preprocessing"""

df = df.drop(columns=['intensity'])
df

def predicted_categories(category):
  if category == 'very negative' or category == 'negative':
    return 'negative'
  elif category == 'neutral':
    return 'neutral'
  else:
    return 'positive'

df['predicted']=df['predicted'].apply(predicted_categories)
df

predicted = pd.get_dummies(df.predicted)
df_baru = pd.concat([df, predicted], axis=1)
df_baru = df_baru.drop(columns='predicted')
df_baru

post = df_baru['posts'].values
label = df_baru[['negative', 'neutral', 'positive']].values

from sklearn.model_selection import train_test_split
post_latih, post_test, label_latih, label_test = train_test_split(post, label, test_size=0.2)

len(df_baru['posts'])

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=10391, oov_token='x')
tokenizer.fit_on_texts(post_latih)
tokenizer.fit_on_texts(post_test)

sekuens_latih = tokenizer.texts_to_sequences(post_latih)
sekuens_test = tokenizer.texts_to_sequences(post_test)

padded_latih = pad_sequences(sekuens_latih)
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=10000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.90 and logs.get('val_accuracy') > 0.75 ):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

num_epochs = 20

history = model.fit(padded_latih, label_latih, epochs=num_epochs,
                    validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()